####################################
# Almanac Reference Config File #
####################################

almanac {

  # spark://127.0.0.1@7077,127.0.0.2@7077,127.0.0.3@7077
  # or a local spark://host@7077
  # This defaults to local
  spark {
    master = "local[4]"
//    master = "spark://spark_master@7077"
    # Would normally be `ms` in config but Spark just wants the Long
    streaming.batch.duration = 1000
    ui.enabled = false
    cleaner.ttl = 3600
    serializer = "org.apache.spark.serializer.KryoSerializer"
  }

  cassandra {
    script.creation.path = "create_almanac_keyspace.cql"
    connection.host = "dev"
    keyspace = "almanac"
    table.metrics = "metrics"
    table.facts = "facts"
  }

  kafka {
    metadata.broker.list = "dev:9092"
    zookeeper.connect = "dev:2181"

    topic.metric {
      name = "almanac.metrics"
      partition.num = 1
      replication.factor = 1
    }

    group.id = "1234"
    timeOut = "3000"
    bufferSize = "100"
    clientId = "almanac.engine"

    key.serializer.class = "almanac.kafka.MetricKeySerializer"
    serializer.class = "almanac.kafka.MetricValueSerializer"
  }

  aggregation {
    # schedule.time = ["MINUTE", "HOUR", "DAY", "EVER"]
    schedule.time = ["MINUTE", "EVER"]
    # schedule.geo = [6, 4, 2, 0]
    schedule.geo = [4, 0]
  }

}

akka {
  loglevel = DEBUG
  stdout-loglevel = WARNING

  loggers = ["akka.event.slf4j.Slf4jLogger"]
}